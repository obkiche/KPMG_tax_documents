{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67510768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krist\\anaconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import gensim\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c32f2a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Numac</th>\n",
       "      <th>Link FR</th>\n",
       "      <th>Link NL</th>\n",
       "      <th>Text</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Summary_1</th>\n",
       "      <th>Summary_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/14/2020</td>\n",
       "      <td>REGION DE BRUXELLES-CAPITALE\\nREGION DE BRUXEL...</td>\n",
       "      <td>2020010053</td>\n",
       "      <td>http://www.ejustice.just.fgov.be/cgi/article.p...</td>\n",
       "      <td>http://www.ejustice.just.fgov.be/cgi/article_b...</td>\n",
       "      <td>NL FR\\nbelgiëlex.be   -  Kruispuntbank Wetgevi...</td>\n",
       "      <td>: 2020010053 BRUSSELS HOOFDSTEDELIJK GEWEST 8...</td>\n",
       "      <td>Demissionair minister van Financiën, belast me...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/24/2020</td>\n",
       "      <td>MINISTERE DE LA COMMUNAUTE FRANCAISE\\n20 DECEM...</td>\n",
       "      <td>2020010214</td>\n",
       "      <td>http://www.ejustice.just.fgov.be/cgi/article.p...</td>\n",
       "      <td>http://www.ejustice.just.fgov.be/cgi/article_b...</td>\n",
       "      <td>NL FR\\n\\neinde eerste woord laatste woord\\nPub...</td>\n",
       "      <td>: 2020010214 MINISTERIE VAN DE FRANSE GEMEENS...</td>\n",
       "      <td>De Franse Gemeenschap en de Executieve van de ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/28/2020</td>\n",
       "      <td>SERVICE PUBLIC FEDERAL FINANCES\\n20 JANVIER 20...</td>\n",
       "      <td>2020040138</td>\n",
       "      <td>http://www.ejustice.just.fgov.be/cgi/article.p...</td>\n",
       "      <td>http://www.ejustice.just.fgov.be/cgi/article_b...</td>\n",
       "      <td>NL FR\\nbelgiëlex.be   -  Kruispuntbank Wetgevi...</td>\n",
       "      <td>: 2020040138 FEDERALE OVERHEIDSDIENST FINANCI...</td>\n",
       "      <td>De ministers van Financiën en de staatssecreta...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/28/2020</td>\n",
       "      <td>SERVICE PUBLIC FEDERAL FINANCES\\n20 JANVIER 20...</td>\n",
       "      <td>2020020094</td>\n",
       "      <td>http://www.ejustice.just.fgov.be/cgi/article.p...</td>\n",
       "      <td>http://www.ejustice.just.fgov.be/cgi/article_b...</td>\n",
       "      <td>NL FR\\nbelgiëlex.be   -  Kruispuntbank Wetgevi...</td>\n",
       "      <td>: 2020020094 FEDERALE OVERHEIDSDIENST FINANCI...</td>\n",
       "      <td>Het ministerie van Financiën heeft het ministe...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/28/2020</td>\n",
       "      <td>SERVICE PUBLIC FEDERAL FINANCES\\nAdministratio...</td>\n",
       "      <td>2020010193</td>\n",
       "      <td>http://www.ejustice.just.fgov.be/cgi/article.p...</td>\n",
       "      <td>http://www.ejustice.just.fgov.be/cgi/article_b...</td>\n",
       "      <td>NL FR\\n\\neinde eerste woord laatste woord\\nPub...</td>\n",
       "      <td>: 2020010193 FEDERALE OVERHEIDSDIENST FINANCI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                              Title       Numac  \\\n",
       "0  1/14/2020  REGION DE BRUXELLES-CAPITALE\\nREGION DE BRUXEL...  2020010053   \n",
       "1  1/24/2020  MINISTERE DE LA COMMUNAUTE FRANCAISE\\n20 DECEM...  2020010214   \n",
       "2  1/28/2020  SERVICE PUBLIC FEDERAL FINANCES\\n20 JANVIER 20...  2020040138   \n",
       "3  1/28/2020  SERVICE PUBLIC FEDERAL FINANCES\\n20 JANVIER 20...  2020020094   \n",
       "4  1/28/2020  SERVICE PUBLIC FEDERAL FINANCES\\nAdministratio...  2020010193   \n",
       "\n",
       "                                             Link FR  \\\n",
       "0  http://www.ejustice.just.fgov.be/cgi/article.p...   \n",
       "1  http://www.ejustice.just.fgov.be/cgi/article.p...   \n",
       "2  http://www.ejustice.just.fgov.be/cgi/article.p...   \n",
       "3  http://www.ejustice.just.fgov.be/cgi/article.p...   \n",
       "4  http://www.ejustice.just.fgov.be/cgi/article.p...   \n",
       "\n",
       "                                             Link NL  \\\n",
       "0  http://www.ejustice.just.fgov.be/cgi/article_b...   \n",
       "1  http://www.ejustice.just.fgov.be/cgi/article_b...   \n",
       "2  http://www.ejustice.just.fgov.be/cgi/article_b...   \n",
       "3  http://www.ejustice.just.fgov.be/cgi/article_b...   \n",
       "4  http://www.ejustice.just.fgov.be/cgi/article_b...   \n",
       "\n",
       "                                                Text  \\\n",
       "0  NL FR\\nbelgiëlex.be   -  Kruispuntbank Wetgevi...   \n",
       "1  NL FR\\n\\neinde eerste woord laatste woord\\nPub...   \n",
       "2  NL FR\\nbelgiëlex.be   -  Kruispuntbank Wetgevi...   \n",
       "3  NL FR\\nbelgiëlex.be   -  Kruispuntbank Wetgevi...   \n",
       "4  NL FR\\n\\neinde eerste woord laatste woord\\nPub...   \n",
       "\n",
       "                                        Cleaned Text  \\\n",
       "0   : 2020010053 BRUSSELS HOOFDSTEDELIJK GEWEST 8...   \n",
       "1   : 2020010214 MINISTERIE VAN DE FRANSE GEMEENS...   \n",
       "2   : 2020040138 FEDERALE OVERHEIDSDIENST FINANCI...   \n",
       "3   : 2020020094 FEDERALE OVERHEIDSDIENST FINANCI...   \n",
       "4   : 2020010193 FEDERALE OVERHEIDSDIENST FINANCI...   \n",
       "\n",
       "                                           Summary_1  Summary_2  \n",
       "0  Demissionair minister van Financiën, belast me...        NaN  \n",
       "1  De Franse Gemeenschap en de Executieve van de ...        NaN  \n",
       "2  De ministers van Financiën en de staatssecreta...        NaN  \n",
       "3  Het ministerie van Financiën heeft het ministe...        NaN  \n",
       "4                                                NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('KPMG Tax Case - CSV_Summarized.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f180ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Het ministerie van Financiën heeft een model van de aanvraag van certificaat en van certificaat bedoeld in artikel 442bis van het Wetboek van de inkomstenbelastingen 1992 zoals van toepassing op de onroerende voorheffing herzien.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Summary_1'][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0201791",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b5a0d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tags']=\"\"\n",
    "df['Tag text']=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfec239",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df.iterrows():\n",
    "\n",
    "    nlp = spacy.load('nl_core_news_sm')\n",
    "    text = df.loc[idx, 'Cleaned Text']\n",
    "    tokenized = nlp(text)\n",
    "    tokens = [token.text for token in tokenized]\n",
    "\n",
    "    stopwords = spacy.lang.nl.stop_words.STOP_WORDS\n",
    "\n",
    "    text_no_stop = [lemma for lemma in tokens if lemma not in stopwords]\n",
    "    cleaned = ' '.join(text_no_stop)\n",
    "\n",
    "    df.loc[idx,'Tag text'] = cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab697052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b5cd4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bf327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# TfidfVectorizer \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# set of documents\n",
    "\n",
    "train = \n",
    "test = \n",
    "# instantiate the vectorizer object\n",
    "\n",
    "\n",
    "tfidfvectorizer = TfidfVectorizer(analyzer='word',stop_words= 'english')\n",
    "\n",
    "# convert th documents into a matrix\n",
    "\n",
    "\n",
    "tfidf_wm = tfidfvectorizer.fit_transform(train)\n",
    "\n",
    "#retrieve the terms found in the corpora\n",
    "# if we take same parameters on both Classes(CountVectorizer and TfidfVectorizer) , it will give same output of get_feature_names() methods)\n",
    "#count_tokens = tfidfvectorizer.get_feature_names() # no difference\n",
    "\n",
    "\n",
    "tfidf_tokens = tfidfvectorizer.get_feature_names()\n",
    "\n",
    "df_tfidfvect = pd.DataFrame(data = tfidf_wm.toarray(),index = ['Doc1','Doc2'],columns = tfidf_tokens)\n",
    "\n",
    "\n",
    "print(\"\\nTD-IDF Vectorizer\\n\")\n",
    "print(df_tfidfvect)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99599a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Convert to document-term matrix\n",
    "vectoriser = CountVectorizer(analyzer=preprocess_text)\n",
    "example_matrix = vectoriser.fit_transform(df['Summary_1'])\n",
    "# Extract feature/term names\n",
    "feature_names = vectoriser.get_feature_names()\n",
    "# Inspect document-term matrix\n",
    "pd.DataFrame.sparse.from_spmatrix(example_matrix, \n",
    "                                  columns=feature_names)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7da015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect topics\n",
    "def describe_topics(lda, feature_names, top_n_words=7, show_weight=False):\n",
    "    \"\"\"Print top n words for each topic from lda model.\"\"\"\n",
    "    normalised_weights = lda.components_ / lda.components_.sum(axis=1)[:, np.newaxis]\n",
    "    for i, weights in enumerate(normalised_weights):  \n",
    "        print(f\"********** Topic {i+1} **********\")\n",
    "        if show_weight:\n",
    "            feature_weights = [*zip(np.round(weights, 4), feature_names)]\n",
    "            feature_weights.sort(reverse=True)\n",
    "            print(feature_weights[:top_n_words], '\\n')\n",
    "        else:\n",
    "            top_words = [feature_names[i] for i in weights.argsort()[:-top_n_words-1:-1]]\n",
    "            print(top_words, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8837fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article:  5\n",
      "********** Topic 1 **********\n",
      "[(0.0087, 'één'), (0.0087, 'wijziging'), (0.0087, 'wetten'), (0.0087, 'wetenschappen'), (0.0087, 'wet'), (0.0087, 'waaruit'), (0.0087, 'voorzien')] \n",
      "\n",
      "********** Topic 2 **********\n",
      "[(0.0087, 'één'), (0.0087, 'wijziging'), (0.0087, 'wetten'), (0.0087, 'wetenschappen'), (0.0087, 'wet'), (0.0087, 'waaruit'), (0.0087, 'voorzien')] \n",
      "\n",
      "********** Topic 3 **********\n",
      "[(0.0087, 'één'), (0.0087, 'wijziging'), (0.0087, 'wetten'), (0.0087, 'wetenschappen'), (0.0087, 'wet'), (0.0087, 'waaruit'), (0.0087, 'voorzien')] \n",
      "\n",
      "********** Topic 4 **********\n",
      "[(0.0087, 'één'), (0.0087, 'wijziging'), (0.0087, 'wetten'), (0.0087, 'wetenschappen'), (0.0087, 'wet'), (0.0087, 'waaruit'), (0.0087, 'voorzien')] \n",
      "\n",
      "********** Topic 5 **********\n",
      "[(0.0087, 'één'), (0.0087, 'wijziging'), (0.0087, 'wetten'), (0.0087, 'wetenschappen'), (0.0087, 'wet'), (0.0087, 'waaruit'), (0.0087, 'voorzien')] \n",
      "\n",
      "********** Topic 6 **********\n",
      "[(0.0087, 'één'), (0.0087, 'wijziging'), (0.0087, 'wetten'), (0.0087, 'wetenschappen'), (0.0087, 'wet'), (0.0087, 'waaruit'), (0.0087, 'voorzien')] \n",
      "\n",
      "********** Topic 7 **********\n",
      "[(0.025, 'onderwijs'), (0.0232, 'sociale'), (0.0232, 'promotie'), (0.0178, 'afdeling'), (0.016, 'gelet'), (0.0142, 'hoger'), (0.0124, 'type')] \n",
      "\n",
      "********** Topic 8 **********\n",
      "[(0.0087, 'één'), (0.0087, 'wijziging'), (0.0087, 'wetten'), (0.0087, 'wetenschappen'), (0.0087, 'wet'), (0.0087, 'waaruit'), (0.0087, 'voorzien')] \n",
      "\n",
      "********** Topic 9 **********\n",
      "[(0.0087, 'één'), (0.0087, 'wijziging'), (0.0087, 'wetten'), (0.0087, 'wetenschappen'), (0.0087, 'wet'), (0.0087, 'waaruit'), (0.0087, 'voorzien')] \n",
      "\n",
      "********** Topic 10 **********\n",
      "[(0.0087, 'één'), (0.0087, 'wijziging'), (0.0087, 'wetten'), (0.0087, 'wetenschappen'), (0.0087, 'wet'), (0.0087, 'waaruit'), (0.0087, 'voorzien')] \n",
      "\n",
      "None\n",
      "Article:  6\n",
      "********** Topic 1 **********\n",
      "[(0.0159, 'zie'), (0.0159, 'woorden'), (0.0159, 'wijziging'), (0.0159, 'wetboek'), (0.0159, 'voor'), (0.0159, 'uitvoeringsbesluiten'), (0.0159, 'uitvoering')] \n",
      "\n",
      "********** Topic 2 **********\n",
      "[(0.0159, 'zie'), (0.0159, 'woorden'), (0.0159, 'wijziging'), (0.0159, 'wetboek'), (0.0159, 'voor'), (0.0159, 'uitvoeringsbesluiten'), (0.0159, 'uitvoering')] \n",
      "\n",
      "********** Topic 3 **********\n",
      "[(0.0159, 'zie'), (0.0159, 'woorden'), (0.0159, 'wijziging'), (0.0159, 'wetboek'), (0.0159, 'voor'), (0.0159, 'uitvoeringsbesluiten'), (0.0159, 'uitvoering')] \n",
      "\n",
      "********** Topic 4 **********\n",
      "[(0.0159, 'zie'), (0.0159, 'woorden'), (0.0159, 'wijziging'), (0.0159, 'wetboek'), (0.0159, 'voor'), (0.0159, 'uitvoeringsbesluiten'), (0.0159, 'uitvoering')] \n",
      "\n",
      "********** Topic 5 **********\n",
      "[(0.0159, 'zie'), (0.0159, 'woorden'), (0.0159, 'wijziging'), (0.0159, 'wetboek'), (0.0159, 'voor'), (0.0159, 'uitvoeringsbesluiten'), (0.0159, 'uitvoering')] \n",
      "\n",
      "********** Topic 6 **********\n",
      "[(0.0159, 'zie'), (0.0159, 'woorden'), (0.0159, 'wijziging'), (0.0159, 'wetboek'), (0.0159, 'voor'), (0.0159, 'uitvoeringsbesluiten'), (0.0159, 'uitvoering')] \n",
      "\n",
      "********** Topic 7 **********\n",
      "[(0.0159, 'zie'), (0.0159, 'woorden'), (0.0159, 'wijziging'), (0.0159, 'wetboek'), (0.0159, 'voor'), (0.0159, 'uitvoeringsbesluiten'), (0.0159, 'uitvoering')] \n",
      "\n",
      "********** Topic 8 **********\n",
      "[(0.0159, 'zie'), (0.0159, 'woorden'), (0.0159, 'wijziging'), (0.0159, 'wetboek'), (0.0159, 'voor'), (0.0159, 'uitvoeringsbesluiten'), (0.0159, 'uitvoering')] \n",
      "\n",
      "********** Topic 9 **********\n",
      "[(0.0159, 'zie'), (0.0159, 'woorden'), (0.0159, 'wijziging'), (0.0159, 'wetboek'), (0.0159, 'voor'), (0.0159, 'uitvoeringsbesluiten'), (0.0159, 'uitvoering')] \n",
      "\n",
      "********** Topic 10 **********\n",
      "[(0.0458, 'zie'), (0.0458, 'voor'), (0.0458, 'tabel'), (0.0458, 'raadpleging'), (0.0427, 'beeld'), (0.0181, 'december'), (0.0181, '2019')] \n",
      "\n",
      "None\n",
      "Article:  7\n",
      "********** Topic 1 **********\n",
      "[(0.0227, 'woorden'), (0.0227, 'wijzigingen'), (0.0227, 'wijziging'), (0.0227, 'voormelde'), (0.0227, 'volgende'), (0.0227, 'vervangen'), (0.0227, 'stuk')] \n",
      "\n",
      "********** Topic 2 **********\n",
      "[(0.0227, 'woorden'), (0.0227, 'wijzigingen'), (0.0227, 'wijziging'), (0.0227, 'voormelde'), (0.0227, 'volgende'), (0.0227, 'vervangen'), (0.0227, 'stuk')] \n",
      "\n",
      "********** Topic 3 **********\n",
      "[(0.0576, 'woorden'), (0.0576, 'pct'), (0.034, 'vervangen'), (0.034, 'december'), (0.034, '25'), (0.034, '2019'), (0.0281, 'staatsblad')] \n",
      "\n",
      "********** Topic 4 **********\n",
      "[(0.0227, 'woorden'), (0.0227, 'wijzigingen'), (0.0227, 'wijziging'), (0.0227, 'voormelde'), (0.0227, 'volgende'), (0.0227, 'vervangen'), (0.0227, 'stuk')] \n",
      "\n",
      "********** Topic 5 **********\n",
      "[(0.0227, 'woorden'), (0.0227, 'wijzigingen'), (0.0227, 'wijziging'), (0.0227, 'voormelde'), (0.0227, 'volgende'), (0.0227, 'vervangen'), (0.0227, 'stuk')] \n",
      "\n",
      "********** Topic 6 **********\n",
      "[(0.0227, 'woorden'), (0.0227, 'wijzigingen'), (0.0227, 'wijziging'), (0.0227, 'voormelde'), (0.0227, 'volgende'), (0.0227, 'vervangen'), (0.0227, 'stuk')] \n",
      "\n",
      "********** Topic 7 **********\n",
      "[(0.0227, 'woorden'), (0.0227, 'wijzigingen'), (0.0227, 'wijziging'), (0.0227, 'voormelde'), (0.0227, 'volgende'), (0.0227, 'vervangen'), (0.0227, 'stuk')] \n",
      "\n",
      "********** Topic 8 **********\n",
      "[(0.0227, 'woorden'), (0.0227, 'wijzigingen'), (0.0227, 'wijziging'), (0.0227, 'voormelde'), (0.0227, 'volgende'), (0.0227, 'vervangen'), (0.0227, 'stuk')] \n",
      "\n",
      "********** Topic 9 **********\n",
      "[(0.0227, 'woorden'), (0.0227, 'wijzigingen'), (0.0227, 'wijziging'), (0.0227, 'voormelde'), (0.0227, 'volgende'), (0.0227, 'vervangen'), (0.0227, 'stuk')] \n",
      "\n",
      "********** Topic 10 **********\n",
      "[(0.0227, 'woorden'), (0.0227, 'wijzigingen'), (0.0227, 'wijziging'), (0.0227, 'voormelde'), (0.0227, 'volgende'), (0.0227, 'vervangen'), (0.0227, 'stuk')] \n",
      "\n",
      "None\n",
      "Article:  8\n",
      "********** Topic 1 **********\n",
      "[(0.0046, 'zevende'), (0.0046, 'woning'), (0.0046, 'wijzigingen'), (0.0046, 'wijziging'), (0.0046, 'wib'), (0.0046, 'wetboek'), (0.0046, 'wet')] \n",
      "\n",
      "********** Topic 2 **********\n",
      "[(0.0151, 'artikel'), (0.0127, 'wetboek'), (0.0127, '2019'), (0.0113, '2020'), (0.0108, 'aanslagjaar'), (0.0098, 'lid'), (0.0098, 'inkomstenbelastingen')] \n",
      "\n",
      "********** Topic 3 **********\n",
      "[(0.0046, 'zevende'), (0.0046, 'woning'), (0.0046, 'wijzigingen'), (0.0046, 'wijziging'), (0.0046, 'wib'), (0.0046, 'wetboek'), (0.0046, 'wet')] \n",
      "\n",
      "********** Topic 4 **********\n",
      "[(0.0046, 'zevende'), (0.0046, 'woning'), (0.0046, 'wijzigingen'), (0.0046, 'wijziging'), (0.0046, 'wib'), (0.0046, 'wetboek'), (0.0046, 'wet')] \n",
      "\n",
      "********** Topic 5 **********\n",
      "[(0.0046, 'zevende'), (0.0046, 'woning'), (0.0046, 'wijzigingen'), (0.0046, 'wijziging'), (0.0046, 'wib'), (0.0046, 'wetboek'), (0.0046, 'wet')] \n",
      "\n",
      "********** Topic 6 **********\n",
      "[(0.0046, 'zevende'), (0.0046, 'woning'), (0.0046, 'wijzigingen'), (0.0046, 'wijziging'), (0.0046, 'wib'), (0.0046, 'wetboek'), (0.0046, 'wet')] \n",
      "\n",
      "********** Topic 7 **********\n",
      "[(0.0046, 'zevende'), (0.0046, 'woning'), (0.0046, 'wijzigingen'), (0.0046, 'wijziging'), (0.0046, 'wib'), (0.0046, 'wetboek'), (0.0046, 'wet')] \n",
      "\n",
      "********** Topic 8 **********\n",
      "[(0.0046, 'zevende'), (0.0046, 'woning'), (0.0046, 'wijzigingen'), (0.0046, 'wijziging'), (0.0046, 'wib'), (0.0046, 'wetboek'), (0.0046, 'wet')] \n",
      "\n",
      "********** Topic 9 **********\n",
      "[(0.0046, 'zevende'), (0.0046, 'woning'), (0.0046, 'wijzigingen'), (0.0046, 'wijziging'), (0.0046, 'wib'), (0.0046, 'wetboek'), (0.0046, 'wet')] \n",
      "\n",
      "********** Topic 10 **********\n",
      "[(0.0046, 'zevende'), (0.0046, 'woning'), (0.0046, 'wijzigingen'), (0.0046, 'wijziging'), (0.0046, 'wib'), (0.0046, 'wetboek'), (0.0046, 'wet')] \n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krist\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\krist\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\krist\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\krist\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m5\u001b[39m:\u001b[38;5;241m20\u001b[39m]\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m      8\u001b[0m     corpus \u001b[38;5;241m=\u001b[39m [df\u001b[38;5;241m.\u001b[39mloc[idx,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTag text\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m---> 10\u001b[0m     example_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     feature_names \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mget_feature_names()\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# print(tfidf_matrix.toarray())\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Inspect document-term matrix\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2068\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2061\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2062\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2063\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2064\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2065\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2066\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2067\u001b[0m )\n\u001b[1;32m-> 2068\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2070\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2071\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1328\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1320\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1321\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1322\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1323\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1324\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1325\u001b[0m             )\n\u001b[0;32m   1326\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1328\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1331\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1218\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1216\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[0;32m   1217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[1;32m-> 1218\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1219\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1220\u001b[0m         )\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indptr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[0;32m   1223\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create TfidfVectorizer object\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "\n",
    "corpus = df['Tag text']\n",
    "    \n",
    "example_matrix = vectorizer.fit_transform(corpus)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "    \n",
    "# print(tfidf_matrix.toarray())\n",
    "    \n",
    "# Inspect document-term matrix\n",
    "    \n",
    "pd.DataFrame.sparse.from_spmatrix(example_matrix, \n",
    "                                  columns=feature_names)\n",
    "    \n",
    "# Build lda model\n",
    "lda = LatentDirichletAllocation(n_components=10, random_state=45)\n",
    "lda.fit(example_matrix)\n",
    "    \n",
    "print(describe_topics(lda, feature_names, show_weight=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af2e02ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  : 2020040323 BRUSSELS HOOFDSTEDELIJK GEWEST 11 FEBRUARI 2020 . - Ministerieel besluit vaststelling modellen aanvraag certificaat certificaat bedoeld artikel 442bis Wetboek inkomstenbelastingen 1992 toepassing onroerende voorheffing    De Minister Brusselse Hoofdstedelijke Regering , belast Financiën Begroting , Gelet bijzondere wet 16 januari 1989 financiering Gemeenschappen Gewesten , artikel 5 ; Gelet Wetboek inkomstenbelastingen 1992 toepassing onroerende voorheffing , artikel 442bis ,   5 , gewijzigd ordonnantie 7 december 2017 houdende diverse bepalingen licht overname dienst onroerende voorheffing wijziging ordonnantie 21 december 2012 vaststelling fiscale procedure Brussels Hoofdstedelijk Gewest ; Gelet besluit Brusselse Hoofdstedelijke Regering 30 november 2017 aanstelling ambtenaren kader overname dienst onroerende voorheffing 1 januari 2018 , artikel 7 ; Gelet gelijke kansentest overeenkomstig artikel 2 ordonnantie 4 oktober 2018 invoering gelijke kansentest uitgevoerd 13 januari 2020 ; Overwegende ministerieel besluit reglementaire voorschriften bevat zin artikel 3 ,   1 , lid , gecoördineerde wetten Raad State 12 januari 1973 , onderworpen advies Raad State , afdeling Wetgeving , Besluit : Artikel 1 . Het model aanvraag , bedoeld artikel 442bis ,   5 , Wetboek inkomstenbelastingen 1992 toepassing onroerende voorheffing , hernomen bijlage 1 besl'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tag text'][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae63012",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
